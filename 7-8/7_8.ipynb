{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新闻抄袭模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import timeit\n",
    "def token(string):\n",
    "    return ' '.join(re.findall(r'[^\\d\\W]+', string))\n",
    "def cut(string):\n",
    "    return ' '.join(jieba.cut(string))\n",
    "def clock(func):\n",
    "    def clocked(*args, **kwargs):\n",
    "        t0 = timeit.default_timer()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = timeit.default_timer() - t0\n",
    "        name = func.__name__\n",
    "        arg_str = ', '.join(repr(arg) for arg in args)\n",
    "        print(elapsed,'s')\n",
    "        #print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, arg_str, result))\n",
    "        return result\n",
    "    return clocked\n",
    "def typeof(variate):\n",
    "    type=None\n",
    "    if isinstance(variate,int):\n",
    "        type = \"int\"\n",
    "    elif isinstance(variate,str):\n",
    "        type = \"str\"\n",
    "    elif isinstance(variate,float):\n",
    "        type = \"float\"\n",
    "    elif isinstance(variate,list):\n",
    "        type = \"list\"\n",
    "    elif isinstance(variate,tuple):\n",
    "        type = \"tuple\"\n",
    "    elif isinstance(variate,dict):\n",
    "        type = \"dict\"\n",
    "    elif isinstance(variate,set):\n",
    "        type = \"set\"\n",
    "    print(type)\n",
    "    return type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.743 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('sqlResult_1558435.csv', encoding='gb18030').fillna(' ')\n",
    "train = [cut(token(dataset['content'][i])) for i in range(len(dataset))]\n",
    "y = [1 if dataset['source'][i] == '新华社' else 0 for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 数据不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778051801676133\n"
     ]
    }
   ],
   "source": [
    "data_pos = sum(y)/len(y)\n",
    "print(data_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, token_pattern=r\"(?u)\\b\\w+\\b\", max_df = 1.0,\n",
    "                                 stop_words = None,vocabulary = None )\n",
    "train_vec = vectorizer.fit_transform(train)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_vec, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "@clock\n",
    "def get_performance(clf, x_, y_):\n",
    "    y_hat = clf.predict(x_)\n",
    "    print('f1_score is: {}'.format(f1_score(y_, y_hat)))\n",
    "    print('accuracy is: {}'.format(accuracy_score(y_, y_hat)))\n",
    "    print('percision is: {}'.format(precision_score(y_, y_hat)))\n",
    "    print('recall is: {}'.format(recall_score(y_, y_hat)))\n",
    "    #print('roc_auc is: {}'.format(roc_auc_score(y_, y_hat)))\n",
    "    #print('confusion matrix: \\n{}'.format(confusion_matrix(y_, y_hat, labels=[0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### KNeighborsClassifier\n",
    "\"\"\"\n",
    "时间：几乎不需要训练，测试时间长，因为需要和所有的训练集作计算。\n",
    "空间：占用内存大（需要保存所有样本）\n",
    "用法：算法原理简单，超参数少\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028504303769475284 s\n",
      "f1_score is: 0.8935138691692349\n",
      "accuracy is: 0.8284327400546784\n",
      "percision is: 0.9839829151094501\n",
      "recall is: 0.8182798426994798\n",
      "72.51482860189614 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "@clock\n",
    "def KNN(x_train, y_train):\n",
    "    clf = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform', algorithm = 'auto')\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(KNN(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "194.28275526579648 s\n",
      "f1_score is: 0.9484034331941202\n",
      "accuracy is: 0.9124588517547285\n",
      "percision is: 0.9847708802840948\n",
      "recall is: 0.914626411264747\n",
      "64.72239086886356 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "@clock\n",
    "def KNN(x_train, y_train):\n",
    "    clf = KNeighborsClassifier()\n",
    "    param_grid = { 'n_neighbors' : [i for i in range(1,3)]}\n",
    "    grid = GridSearchCV(clf, param_grid, cv = 2, scoring='accuracy',n_jobs = -1)\n",
    "    clf = grid.fit(x_train, y_train)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    return clf\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(KNN(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### BeyesisClassifier\n",
    "\"\"\"\n",
    "时间：训练和测试均很快\n",
    "空间：占用内存少\n",
    "用法：条件独立假设，通常不一定可行；不需要调参\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2201603363319009 s\n",
      "f1_score is: 0.8884335001847683\n",
      "accuracy is: 0.8147073592590526\n",
      "percision is: 0.9444325405328191\n",
      "recall is: 0.8387035392617024\n",
      "0.08664537942968309 s\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def GNB(x_train, y_train):\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    gnb = BernoulliNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    return gnb\n",
    "\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(GNB(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LogisticRegression Classifier\n",
    "\"\"\"\n",
    "时间：线性模型，训练和预测的速度快\n",
    "空间：占用内存少\n",
    "用法：模型简单，但是泛化能力强\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.895269985026971 s\n",
      "f1_score is: 0.9943888286679845\n",
      "accuracy is: 0.9901802153657312\n",
      "percision is: 0.9996794871794872\n",
      "recall is: 0.9891538754281365\n",
      "0.03404405297987978 s\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def LG(x_train, y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0, class_weight='balanced' \n",
    "                             ,solver='liblinear').fit(x_train, y_train)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(LG(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SVM Classifier\n",
    "\"\"\"\n",
    "缺点：模型本质上是求解二次规划问题，复杂且时间开销大，不实用于大型数据集\n",
    "优点：\n",
    "1）占用内存少，只需保存少数支持向量，通过支持向量便可以计算出分类器\n",
    "2）利用核函数性质可以轻松地映射到高维空间进行分类，非常高效\n",
    "3）即使在数据维度比样本数量大的情况下仍然有效\n",
    "4）需要调优的超参数：C-误差惩罚项；核函数选择\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\env_nlp\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\env_nlp\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6608.065565968143 s\n",
      "f1_score is: 0.706880997293529\n",
      "accuracy is: 0.6011828376945824\n",
      "percision is: 0.9998839907192575\n",
      "recall is: 0.5466827349993657\n",
      "653.6304521249003 s\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def SVM(x_train, y_train):\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC(C=1.0, class_weight='balanced',kernel='rbf')\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(SVM(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RandomForest Classifier\n",
    "\"\"\"\n",
    "缺点：\n",
    "1）小数据或者低维数据（特征较少的数据），可能不能产生很好的分类\n",
    "2）相比用于分类，回归的效果差一些\n",
    "优点：\n",
    "1）相比同类算法，准确率高\n",
    "2）有效地运行在大数据、高维度、有缺失值的输入样本\n",
    "3）能够评估各个特征在分类问题上的重要性\n",
    "4）在生成过程中，能够获取到内部生成误差的一种无偏估计\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3704868411049347 s\n",
      "f1_score is: 0.9350093607916554\n",
      "accuracy is: 0.8779780170730347\n",
      "percision is: 0.8779507785032646\n",
      "recall is: 1.0\n",
      "0.0829685387795962 s\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def RF(x_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "#clf.fit(X_test,y_test)\n",
    "get_performance(RF(x_train,y_train),x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
